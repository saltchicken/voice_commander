import pyaudio
import vosk
import json
import numpy as np

def is_silent(chunk, silence_threshold):
    audio_data = np.frombuffer(chunk, dtype=np.int16)
    rms = np.sqrt(np.mean(audio_data**2))
    return rms < silence_threshold

model_path = "vosk-model-en-us-0.22"  # Update with your model path

model = vosk.Model(model_path)

p = pyaudio.PyAudio()
stream = p.open(format=pyaudio.paInt16,
                channels=1,
                rate=16000,
                input=True,
                frames_per_buffer=4000)

print("Listening...")

rec = vosk.KaldiRecognizer(model, 16000)

listening = False

while True:
    data = stream.read(4000)
    
    if len(data) == 0:
        break

    if is_silent(data, 200) and not listening:
        continue
    else:
        print("Now transcribing")
        listening = True


    if rec.AcceptWaveform(data):
        result = rec.Result()
        print(json.loads(result)["text"])
        listening = False
    else:
        partial_result = rec.PartialResult()
        print(partial_result)
        if partial_result:
            partial_text = json.loads(partial_result).get("partial")
            if partial_text and partial_text != "":
                print(partial_text)

